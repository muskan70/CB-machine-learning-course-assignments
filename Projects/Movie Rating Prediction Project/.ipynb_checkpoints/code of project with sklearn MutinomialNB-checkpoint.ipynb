{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "#clean input file\n",
    "def getCleanDocument(inputFile,outputFile):\n",
    "    out=open(outputFile,'w',encoding=\"utf8\")\n",
    "    with open(inputFile,encoding=\"utf8\") as f:\n",
    "        reviews=f.readlines()\n",
    "        \n",
    "    for review in reviews:\n",
    "        cleaned_review=getCleanText(review)\n",
    "        print(cleaned_review,file=out)\n",
    "    \n",
    "    out.close()\n",
    "    \n",
    "#clean a review\n",
    "def getCleanText(text):\n",
    "    text=text.lower()\n",
    "    text=text.replace(\"<br/><br/>\",\" \")\n",
    "    \n",
    "    #Init objects\n",
    "    tokenizer=RegexpTokenizer(r'\\w+')\n",
    "    en_stopwords=set(stopwords.words('english'))\n",
    "    ps=PorterStemmer()\n",
    "    \n",
    "    #Tokenize\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    new_tokens=[token for token in tokens if token not in en_stopwords]\n",
    "    stemmed_tokens=[ps.stem(token) for token in new_tokens]\n",
    "    cleaned_text=' '.join(stemmed_tokens)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train dataset\n",
    "getCleanDocument(\"../../Datasets/IMDB/imdb_trainX.txt\",\"Xtrain.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get test dataset\n",
    "getCleanDocument(\"../../Datasets/IMDB/imdb_testX.txt\",\"Xtest.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "with open(\"Xtrain.txt\",'r') as f:\n",
    "    X_train=f.readlines()\n",
    "print(type(X_train)) \n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "with open(\"Xtest.txt\",'r') as f:\n",
    "    X_test=f.readlines()\n",
    "print(type(X_test)) \n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../Datasets/IMDB/imdb_trainY.txt\",'r') as f:\n",
    "    Y_train=f.readlines()\n",
    "print(type(Y_train)) \n",
    "Y_train=[int(i) for i in Y_train]\n",
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../Datasets/IMDB/imdb_testY.txt\",'r') as f:\n",
    "    Y_test=f.readlines()\n",
    "Y_test=[int(i) for i in Y_test]    \n",
    "print(type(Y_test))\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love movi sinc 7 saw open day touch beauti strongli recommend see movi watch famili far br br mpaa rate pg 13 themat element prolong scene disastor nuditi sexual languag\n",
      "\n",
      "10\n",
      "realli sure make movi weird artsi kind movi watch compel plot charact like kind movi stop watch horrif fascin thing happen screen although first time wife watch make way disturb run bit long nonetheless worthwhil view interest dark movi\n",
      "\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(Y_train[0])\n",
    "print(X_test[0])\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 51229)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "x_vec=cv.fit_transform(X_train)\n",
    "print(x_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 51229)\n"
     ]
    }
   ],
   "source": [
    "xt_vec=cv.transform(X_test)\n",
    "print(xt_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb=MultinomialNB()\n",
    "mnb.fit(x_vec,Y_train)\n",
    "#predictions\n",
    "yt_pred=mnb.predict(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  7  4 10  8  1 10 10  8 10]\n"
     ]
    }
   ],
   "source": [
    "print(yt_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38348"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set accuracy\n",
    "mnb.score(xt_vec,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6744"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train set accuracy\n",
    "mnb.score(x_vec,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
