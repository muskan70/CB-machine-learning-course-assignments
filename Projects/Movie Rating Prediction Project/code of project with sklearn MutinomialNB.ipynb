{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "#clean input file\n",
    "def getCleanDocument(inputFile,outputFile):\n",
    "    out=open(outputFile,'w',encoding=\"utf8\")\n",
    "    with open(inputFile,encoding=\"utf8\") as f:\n",
    "        reviews=f.readlines()\n",
    "        \n",
    "    for review in reviews:\n",
    "        cleaned_review=getCleanText(review)\n",
    "        print(cleaned_review,file=out)\n",
    "    \n",
    "    out.close()\n",
    "    \n",
    "#clean a review\n",
    "def getCleanText(text):\n",
    "    text=text.lower()\n",
    "    text=text.replace(\"<br/><br/>\",\" \")\n",
    "    \n",
    "    #Init objects\n",
    "    tokenizer=RegexpTokenizer(r'\\w+')\n",
    "    en_stopwords=set(stopwords.words('english'))\n",
    "    ps=PorterStemmer()\n",
    "    \n",
    "    #Tokenize\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    new_tokens=[token for token in tokens if token not in en_stopwords]\n",
    "    stemmed_tokens=[ps.stem(token) for token in new_tokens]\n",
    "    cleaned_text=' '.join(stemmed_tokens)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train dataset\n",
    "getCleanDocument(\"../../Datasets/IMDB/imdb_trainX.txt\",\"Xtrain.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get test dataset\n",
    "getCleanDocument(\"../../Datasets/IMDB/imdb_testX.txt\",\"Xtest.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "with open(\"Xtrain.txt\",'r') as f:\n",
    "    X_train=f.readlines()\n",
    "print(type(X_train)) \n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "with open(\"Xtest.txt\",'r') as f:\n",
    "    X_test=f.readlines()\n",
    "print(type(X_test)) \n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../Datasets/IMDB/imdb_trainY.txt\",'r') as f:\n",
    "    Y_train=f.readlines()\n",
    "print(type(Y_train)) \n",
    "Y_train=[int(i) for i in Y_train]\n",
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../Datasets/IMDB/imdb_testY.txt\",'r') as f:\n",
    "    Y_test=f.readlines()\n",
    "Y_test=[int(i) for i in Y_test]    \n",
    "print(type(Y_test))\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love movi sinc 7 saw open day touch beauti strongli recommend see movi watch famili far br br mpaa rate pg 13 themat element prolong scene disastor nuditi sexual languag\n",
      "\n",
      "10\n",
      "realli sure make movi weird artsi kind movi watch compel plot charact like kind movi stop watch horrif fascin thing happen screen although first time wife watch make way disturb run bit long nonetheless worthwhil view interest dark movi\n",
      "\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(Y_train[0])\n",
    "print(X_test[0])\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1577483)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(ngram_range=(1,2))\n",
    "x_vec=cv.fit_transform(X_train)\n",
    "print(x_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1577483)\n"
     ]
    }
   ],
   "source": [
    "xt_vec=cv.transform(X_test)\n",
    "print(xt_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\n",
    "mnb=MultinomialNB(alpha=0.01)\n",
    "mnb.fit(x_vec,Y_train)\n",
    "#predictions\n",
    "yt_pred=mnb.predict(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  8  3  7  7  1 10  9 10 10]\n"
     ]
    }
   ],
   "source": [
    "print(yt_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36888"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test set accuracy\n",
    "mnb.score(xt_vec,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99976"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train set accuracy\n",
    "mnb.score(x_vec,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3856  312  283  260   38   66   34  173]\n",
      " [1345  203  266  262   60   47   17  102]\n",
      " [1112  221  387  424  108  117   25  147]\n",
      " [ 808  165  397  606  201  197   54  207]\n",
      " [ 287   55  156  290  396  449  136  538]\n",
      " [ 295   60  118  227  330  647  234  939]\n",
      " [ 229   39   67  123  201  450  232 1003]\n",
      " [ 487   90  115  168  273  582  389 2895]]\n"
     ]
    }
   ],
   "source": [
    "#Generate Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix=confusion_matrix(Y_test,yt_pred)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5100    0    0    0    0    0    0    0]\n",
      " [   1 2283    0    0    0    0    0    0]\n",
      " [   1    0 2419    0    0    0    0    0]\n",
      " [   0    0    1 2695    0    0    0    0]\n",
      " [   0    0    0    0 2496    0    0    0]\n",
      " [   0    0    0    0    0 3009    0    0]\n",
      " [   0    0    0    0    0    0 2263    0]\n",
      " [   2    0    0    0    0    0    1 4729]]\n"
     ]
    }
   ],
   "source": [
    "#Generate Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix=confusion_matrix(Y_train,mnb.predict(x_vec))\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muskan/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  8 10 10  7  1 10 10 10 10]\n"
     ]
    }
   ],
   "source": [
    "bnb=BernoulliNB(alpha=0)\n",
    "bnb.fit(x_vec,Y_train)\n",
    "#predictions\n",
    "yt_pred=bnb.predict(xt_vec)\n",
    "print(yt_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35216"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(xt_vec,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99984"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(x_vec,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
